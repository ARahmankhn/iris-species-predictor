#!/usr/bin/env python3
"""
Iris Model Training Script
This script trains a Decision Tree classifier on the Iris dataset and saves it for deployment.
Run this script before deploying your Streamlit app to ensure model compatibility.
"""

import pickle
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import os
from datetime import datetime

def load_and_explore_data():
    """Load the Iris dataset and display basic information"""
    print("Loading Iris dataset...")
    iris = load_iris()
    
    # Create DataFrame for easier manipulation
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['target'] = iris.target
    df['species'] = df['target'].map({i: iris.target_names[i] for i in range(len(iris.target_names))})
    
    print(f"\nDataset Shape: {df.shape}")
    print(f"Features: {iris.feature_names}")
    print(f"Target Classes: {iris.target_names}")
    print(f"\nClass Distribution:")
    print(df['species'].value_counts())
    
    print(f"\nDataset Statistics:")
    print(df.describe())
    
    return iris, df

def train_model(X, y, test_size=0.2, random_state=42):
    """Train a Decision Tree classifier"""
    print(f"\nSplitting data: {100-test_size*100:.0f}% train, {test_size*100:.0f}% test")
    
    # Split the data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    print(f"Training set size: {X_train.shape[0]} samples")
    print(f"Test set size: {X_test.shape[0]} samples")
    
    # Create the model
    model = DecisionTreeClassifier(
        criterion='gini',
        splitter='best',
        max_depth=3,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=random_state
    )
    
    print(f"\nTraining Decision Tree Classifier...")
    print(f"Model Parameters:")
    print(f"  - Criterion: {model.criterion}")
    print(f"  - Max Depth: {model.max_depth}")
    print(f"  - Min Samples Split: {model.min_samples_split}")
    print(f"  - Random State: {model.random_state}")
    
    # Train the model
    model.fit(X_train, y_train)
    
    return model, X_train, X_test, y_train, y_test

def evaluate_model(model, X_train, X_test, y_train, y_test, target_names):
    """Evaluate the trained model"""
    print(f"\n" + "="*50)
    print("MODEL EVALUATION")
    print("="*50)
    
    # Training accuracy
    train_pred = model.predict(X_train)
    train_accuracy = accuracy_score(y_train, train_pred)
    print(f"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
    
    # Test accuracy
    test_pred = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, test_pred)
    print(f"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    print(f"Cross-validation Accuracy: {cv_scores.mean():.4f} (¬±{cv_scores.std()*2:.4f})")
    
    # Classification report
    print(f"\nClassification Report:")
    print(classification_report(y_test, test_pred, target_names=target_names))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, test_pred)
    print(f"Confusion Matrix:")
    print(cm)
    
    # Feature importance
    feature_importance = model.feature_importances_
    print(f"\nFeature Importance:")
    for i, importance in enumerate(feature_importance):
        print(f"  {load_iris().feature_names[i]}: {importance:.4f}")
    
    return train_accuracy, test_accuracy, cv_scores.mean()

def save_model(model, feature_names, target_names, filename='deployment.pkl'):
    """Save the trained model and related data"""
    print(f"\n" + "="*50)
    print("SAVING MODEL")
    print("="*50)
    
    # Create the deployment dictionary
    deployment_data = {
        'model': model,
        'feature_names': feature_names,
        'target_names': target_names,
        'model_type': 'DecisionTreeClassifier',
        'training_date': datetime.now().isoformat(),
        'sklearn_version': __import__('sklearn').__version__,
        'model_parameters': model.get_params()
    }
    
    # Save using pickle
    try:
        with open(filename, 'wb') as file:
            pickle.dump(deployment_data, file)
        print(f"‚úÖ Model saved successfully as '{filename}' using pickle")
    except Exception as e:
        print(f"‚ùå Error saving with pickle: {e}")
        return False
    
    # Also save using joblib for better sklearn compatibility
    joblib_filename = filename.replace('.pkl', '.joblib')
    try:
        joblib.dump(deployment_data, joblib_filename)
        print(f"‚úÖ Model also saved as '{joblib_filename}' using joblib")
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: Could not save with joblib: {e}")
    
    # Verify the saved model
    print(f"\nVerifying saved model...")
    try:
        with open(filename, 'rb') as file:
            loaded_data = pickle.load(file)
        
        loaded_model = loaded_data['model']
        print(f"‚úÖ Model loaded successfully!")
        print(f"   Model type: {type(loaded_model).__name__}")
        print(f"   Feature names: {loaded_data['feature_names']}")
        print(f"   Target names: {loaded_data['target_names']}")
        print(f"   Training date: {loaded_data['training_date']}")
        print(f"   Sklearn version: {loaded_data['sklearn_version']}")
        
        # Test a prediction
        iris = load_iris()
        test_sample = iris.data[0:1]  # First sample
        prediction = loaded_model.predict(test_sample)
        probability = loaded_model.predict_proba(test_sample)
        
        print(f"\nTest prediction:")
        print(f"   Input: {test_sample[0]}")
        print(f"   Predicted class: {prediction[0]} ({target_names[prediction[0]]})")
        print(f"   Probabilities: {probability[0]}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error verifying saved model: {e}")
        return False

def create_model_summary(model, train_acc, test_acc, cv_acc):
    """Create a summary report of the model"""
    summary = f"""
IRIS CLASSIFICATION MODEL SUMMARY
{'='*50}

Model Information:
- Algorithm: Decision Tree Classifier
- Max Depth: {model.max_depth}
- Criterion: {model.criterion}
- Random State: {model.random_state}

Performance Metrics:
- Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)
- Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)
- Cross-Validation Accuracy: {cv_acc:.4f} ({cv_acc*100:.2f}%)

Feature Importance:
{chr(10).join([f"- {name}: {imp:.4f}" for name, imp in zip(load_iris().feature_names, model.feature_importances_)])}

Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Scikit-learn Version: {__import__('sklearn').__version__}

Ready for deployment! üöÄ
"""
    return summary

def main():
    """Main training pipeline"""
    print("IRIS SPECIES CLASSIFIER - MODEL TRAINING")
    print("="*60)
    
    # Load and explore data
    iris, df = load_and_explore_data()
    
    # Train model
    model, X_train, X_test, y_train, y_test = train_model(
        iris.data, iris.target, test_size=0.2, random_state=42
    )
    
    # Evaluate model
    train_acc, test_acc, cv_acc = evaluate_model(
        model, X_train, X_test, y_train, y_test, iris.target_names
    )
    
    # Save model
    success = save_model(model, iris.feature_names, iris.target_names)
    
    if success:
        # Print summary
        summary = create_model_summary(model, train_acc, test_acc, cv_acc)
        print(summary)
        
        # Save summary to file
        with open('model_summary.txt', 'w') as f:
            f.write(summary)
        print(f"üìÑ Model summary saved to 'model_summary.txt'")
        
        print(f"\nüéâ Model training completed successfully!")
        print(f"üìÅ Files created:")
        print(f"   - deployment.pkl (main model file)")
        print(f"   - deployment.joblib (alternative format)")
        print(f"   - model_summary.txt (performance summary)")
        print(f"\nüöÄ Your model is ready for Streamlit deployment!")
        
    else:
        print(f"\n‚ùå Model training failed. Please check the errors above.")

if __name__ == "__main__":
    main()
